（人物）LinkedIn高级分析师王益：大数据时代的理想主义和现实主义（图灵访谈）
http://www.ituring.com.cn/article/75445

（王垠的同学。）

王益，LinkedIn高级分析师。
他曾在腾讯担任广告算法和策略的技术总监，在此期间他发明了并行机器学习系统“孔雀”，
它可以从数十亿的用户行为或文本数据中学习到上百万的潜在主题，该系统被应用在腾讯可计算广告业务中。
在此之前，他在Google担任软件工程师，并开发了一个分布式机器学习工具，
这个工具让他获得了2008年的“Google APAC 创新奖”。
王益曾在清华大学和香港城市大学学习，并取得了清华大学机器学习和人工智能的博士学位。
此外，他还是IEEE的高级会员，著有《推荐系统实践》。


不认输


“再想想既然中学时能自学大学课程，当下好歹也该试着突破一下困境吧。
于是从高中数学课本开始看，一直看到机器学习专业的教材。”


你从什么时候开始编程的？
我看别人编程很早。
自己动手是在小学五年级，那时候爸爸买了一台中华学习机，也就是中科院对Apple II的克隆。
长大之后才听说当时台湾宏碁电脑公司也克隆了Apple II，取名叫“小教授”。
当时我的四叔有一台“笔记本”电脑，没有显示器，但是集成了一个肥皂盒那么大的打印机——每输入一行指令，就在纸带上打印出来。
这些都让我好奇和着迷。

我迷恋编程是从初三毕业后的那个暑假：
用6502汇编语言和BASIC语言混合写了一个在电视上显示的“打猎”游戏。
其实那时候386都已经大行其道了，而家里的电脑一直没有更新。
主要原因是妈妈担心我用电脑玩游戏。
高一的寒假，在邻居易金务伯伯（国防科技大学人文与社会科学学院教授）劝说下，爸妈给我买了一台486。

其实体会过编程的乐趣的人，不容易沉迷于游戏 ——因为前者是人设计规则，让机器照着做；
后者是人跟着机器的规则动，有点儿像围栏里的牛一样——当然是前者更有意思。
我从高一开始接触和自学C++语言。
在高中阶段经常逃课，跑回家写程序。好几位老师很担心，多次来家访。
我也很惭愧，但是抵不住编程的诱惑。

我高二的时候自学完了计算机本科专业课程，通过了“程序员”和“高级程序员”认证考试。
这个经历锻炼了我的自学能力，培养了自信，逐渐摆脱了“不如邻居家孩子成绩好”的心理压力。

大学学的是什么专业？
我在国防科技大学读的本科，计算机专业。
这里是银河和天河系列超级计算机的家——每一代机器都是当时的世界顶级水平；
最近一次是2013年6月天河2号夺魁世界第一超级计算机。
新生入校的思想教育就是参观这些机器，绝对让人振奋。

和其他学校相比，国防科大计算机系的软硬件教育都很严格。
比如本科计算机原理课程的大作业通常是用集成电路组装一台计算机，但是在国防科大基本没有集成电路（只有一片很原始的8位ALU）。
换句话说，需要学生自己设计CPU（包括指令集），并且用最基本的电路元器件实现出来。
而那些电阻电容三极管故障率很高，所以构造电脑的过程中要严格测试，规划回避风险。
另一个例子是编译原理的大作业，清华课程要求是“修改PL/1语言的编译器，增加一种语法”，
国防科大的要求是“设计一种语言并且实现其编译器”。
当然清华的课程设置是有道理的——让同学们用最合理的精力和时间付出取得最大的锻炼。
而国防科大的课程设置的目的是——顶级计算技术的薪火相传。
给本科生上课的老师有很多是从1960年代就走在计算机研究最前沿的老教授。

这里有我的恩师李思昆教授——三界“银河功臣”、文职一级（相当于武职的中将）。
国防科大有一个“优异生”制度——选择基础好的本科生当研究生培养。
我从大二开始成为优异生，进了教研室跟李老师学习计算机图形学（computer graphics）。
这比初中时那个“打猎”游戏有意思多了。
当时我开发了一个浏览器插件，可以在网页里嵌入可编程的三维图形效果，并且可编程可配置性比当时各种VRML插件更高。
可惜当时不知道怎么产业化，要不然说不定可以和后来人尽皆知的可编程二维图形技术Flash较量一下。

在大学的学习过程中有什么有趣的学习经历吗？
因为中学时已经自学了本科专业课程，所以那时我经常借口“教研室有任务”逃课，一天到晚泡在实验室里写程序。
长沙夏天的傍晚常有暴雨。
有一次我专注编程没关窗，直到飘进来的雨点把屏幕和眼镜都打湿到看不清了，才意识到。

国防科大是一所军校，体育课都是军体项目：
投手榴弹、5000米跑、三级跳、单双杠三动作到六动作。
我小时候体弱多病，一开始不适应。
我的同学们给了我很多帮助，后来还把我拉进了我们学员队的排球队做候补。
我们学员队长陈传宝（江湖人称“宝哥”）是八一体工队的专业运动员，也给了我很多鼓励。
感谢他们帮我养成了锻炼身体的习惯。
现在公司和家之间有一条biking trail，我经常下午抽一个小时在上面跑8公里；
另外每天骑自行车上下班，往返共一个小时。

你在香港城市大学和清华大学都从事过机器学习方面的学习和研究，你觉得两所大学的学术环境和风格有什么不同？
你在两所大学的收获是什么？

香港的大学的发展历程更像欧美大学，大陆大学的建设深受苏联影响，这是主要区别。
前人之述备矣。对我个人而言，清华百年老校，有温和敦厚的长者气质；
城大始建于上世纪80年代，有青春活泼的氛围。
这可以从我的一段经历讲起：

我从小数学不好。在计算机领域选了图形学，是因为我以为这里数学简单。
我的博士导师周立柱老师是数据库方面的专家，但是他“因材施教”，推荐我去微软亚洲研究院图形学组实习。
但是和研究院汇聚的全国高校精英同学们比起来，我脑子反应慢，研究工作做的不够好，
所以跟周老师又要了一个去城市大学学“有道理的”机器学习的机会。
不料去了以后才发现身边的同学都是数学“童子功”，他们嘴里蹦出来的词儿我都闻所未闻。
午饭时大家顺便聊点儿科学问题，我完全听不懂。
于是陷入深深的自卑感里了，没有勇气面对困难，每天混吃等死。

我在城大的导师刘志强教授一生经历过很多风浪，为人刚毅果敢。
见我一副不可救药的样子，于是决断“你这样不能白拿每个月一万多港元的助研工资，你还是回去吧。”
但是实际上他和周老师商量，把我放在清华深圳研究生院，托付给当时任信息学部主任的钟玉琢老师照顾，他俩每隔一段时间来深圳看我。
可我那时候不知道这些，心理压力叫一个大。
虽然自由选择研究方向，可是在微软和香港都没有做出成绩。
博士读到第四年，一篇论文也没发表过。
一时间心灰意冷，考虑辍学。

可是认输又觉得对不起周老师给的那么多研究机会。
再想想既然中学时能自学大学课程，当下好歹也该试着突破一下困境吧。
于是从高中数学课本开始看，一直看到机器学习专业的教材。
然后能看懂论文，了解最新的研究成果。
随后自己找了一个把机器学习和图形学结合起来的研究方向——用多个摄像头采集人的动作，让机器学习这些动作数据，从而能自动合成三维动画。
全力投入一年半之后，我重新自学了数学课，而且在这个方向上发表了10篇论文。
虽然今天完全看不上当时论文的水平了，但是刘老师很高兴邀我二进香港。

周刘二位导师，一位温和敦厚，让我广泛涉猎，一位刚毅决断，激发我的潜力。
他们并不替我选题和指导我在顶级会议和期刊上发表论文，而是锻炼了我给自己出题的能力。
这对一个博士生来说比解题更重要。我对他们敬佩和感激终身不忘。

在IBM和微软这样的公司实习后，你为什么从此开始了互联网之路？
香港的经历勾起了我对数学和机器学习的兴趣。
于是我主动推迟一年毕业，学习机器学习的主要应用——数据挖掘。
数据挖掘得有数据；IBM是老牌大厂，数据应该积累丰厚，于是我投奔了清华的一位师姐刘世霞，去做实习。
在IBM发表的论文，将就能让我毕业后腆着脸去敲Google的门。

但是真正值得挖掘的数据不在IBM和微软这样的软件和咨询公司，而是在互联网行业。
让我意识到这一点的是我的一位师兄郭奇。
他对学术研究兴趣不大，在搜狗兼职，而且兼得很凶——是搜狗输入法的首创者，也是当时搜狗搜索引擎工程架构的负责人。
“输入法的语言模型训练不就是从大家的输入中总结人类语言的规律吗？”
这句话引导了我后来的工作方向——从大众行为数据中归纳人类智能。
在郭奇启发了我6年之后，出现了一个热词“大数据” 。

大数据时代的理想主义和现实主义


“在大数据时代，先得成为出色的工程师，才能成为了不起的研究员。”


在Google的时候，你参与开发了一个分布式机器学习的工具，这个工具获得了APAC创新奖，并部署在多个Google的产品中。
你在开发这个产品中的角色是什么？有什么样的收获？

Google在亚太地区就一个研究团队，全职做研究的就两个人——张栋和我。
张栋后来去百度，随后创业。他的故事很多人都了解了。
当时我们俩各自做一些研究。最终获奖的是团队成果的集合。
这个团队除了我们俩，还有好几位加州大学、清华、北大、MIT、浙大的实习生，以及几位非常出色的Google工程师。
我负责的一项主要工作是主体模型的分布式机器学习技术。
这个研究是张栋做起来的。他换了研究方向后，我换了一种技术思路接着做。
这一做就是7年，跨越了我在Google和腾讯的职业历程，也影响到我目前的工作。

要说收获的话，有两点体会：
（1）各种互联网服务收集了大量用户行为数据，这些大数据都是长尾分布的；
但是研究领域总体仍然专注在基于指数分布构造的机器学习模型。
这样的模型计算方便，但忽视了数据中长尾的部分，也就忽视了大数据中最重要的部分。 
（2） 每一种有价值的算法，都值得拥有独到的并行计算架构。
做分布式机器学习的人不可迷信特定框架，比如MapReduce、MPI或者Spark，
不要试图套用这些架构来描述各种算法，而要有能力开发自己算法适用的框架。
在大数据时代，先得成为出色的工程师，才能成为了不起的研究员。

这些可能都算是比较新鲜的想法，不一定大家都认同，
但是没关系，我把我亲身经历的很多大数据研究工作，简要描述在《分布式机器学习的故事》这一系列博客里了。
读者自有体会。

在研究之外，我的很多工作在四处出差，把研究成果应用到产品里。
为此我拜访过Google分布在全球很多地方的产品团队。
俗话说“是骡子是马，拉出来溜溜”。
去了之后，先拿产品数据做出实际效果，给产品团队展示之后，才有机会说服他们使用。
这样的工作，也是我们获奖的一个原因。

您致力于把纯研究和业界的需求结合起来，这样做的原因是什么？业界缺乏对于这方面的关注吗？

直接原因是我第一份工作在Google，Google是一个工程师文化极强的公司——这里的老牌研究员个个都是顶级工程师。
而搜索引擎这样的产品的用户体验主要是技术水平决定的。
Google因为有最强大的并行计算技术，所以能索引全球网页和支持精准匹配，所以用户体验第一。
对技术水平的孜孜以求，不仅弱化了传统产品经理的角色，也模糊了工程师和研究员的界限
——每一个追求技术突破的工程师，都自然会去读论文，追踪技术前沿，也就成了研究员。
那么研究员也就别自高自大地指望自己设计了算法交给工程师去实现了。
因为这个原因，Google里虽然有研究员，但是没有研究院，
而且研究员的考核成绩与论文专利没有关系，主要看对产品的贡献。

腾讯的情况和Google的比较类似，都是利用一个平台支撑起很多业务，这样产品线都很丰富。
Google的搜索技术在Gmail、Map、Youtube、Google Now等产品里都有体现；
腾讯用QQ汇聚用户，支持了网站、游戏、社交、无线等很多业务。
丰富的产品线会收集到海量的用户行为；而数据挖掘研究的目标就是从数据中归纳用户行为模式，让产品体验更便捷。
但是处理大数据对硬件和软件都有需求—— 大部分大学和研究院没有足够的计算资源来处理大数据；
并且很多研究员也并不擅长设计适合于自己研发的算法的并行计算架构，
于是往往套用现有架构，容易造成系统性能、容错或者可扩展性方面的限制。

为了帮助学术界和工业界融合，我一方面分享我自己做大规模机器学习的经验，抛砖引玉；
也欢迎教授来公司做访问研究，同学们来做实习；
同时也和腾讯的同事们一起为国际数据挖掘大赛出题，比如KDD Cup 2012和ICME Grand Challenge 2014
——这些比赛题目都是基于真实的业界数据和真实的业界问题。
希望能帮助学界了解业界。
互联网行业里有一些学界业界交融好榜样，比如卡内基梅隆大学的Alexander Smola教授。
他在Yahoo!有丰富的业界经验。
在成为Principle Scientist之后，去卡内基梅隆任教，传授业界积累的大数据挖掘知识。
同时在Google做访问研究，保持研究水平的领先。
我相信将来会有更多研究人员像这样两条胳膊都撸起袖子。

离开Google加入腾讯的原因什么？

这里原因很多。总体来说和Google在中国的业务发展势头不强有关。
另外，作为一个“土博士”，我要是不了解中国互联网行业，会被人笑话浪费机会的。
而要了解中国互联网，腾讯是最好的学校。
这几年我们津津乐道Facebook以及它支持起的Zynga这样的游戏公司。
但是在此之前很多年，腾讯就成功的经营了世界上最大的社交网络QQ，并且依托它成就了网站、游戏、社交等很多业务群。
其中社交业务群下的QZone这一个产品拥有的用户数量就和Facebook同量级。
今天，在无线互联网上，微信又在强力支持游戏、移动支付、和O2O。

Google让我见识和实践了世界一流的大数据技术，腾讯给了我了解互联网业务的机会。这是两家很伟大的公司。

在腾讯的时候，你创造了孔雀这个成功的并行机器学习系统。可以向我们介绍一下这个系统吗？

孔雀是一个主题模型的并行训练系统。
主题模型是一种机器学习方法，它从文本中归纳“语义”，每个“语义”是一组表达同样意思的词。
这个归纳过程通常比较耗费机器和时间；但是一旦归纳结束，得到了主题模型，
那么机器就可以在几毫秒之内理解任何一段文本（搜索词、广告、商品描述或者网页内容）表达的语义，
从而在语义空间里比较用户意图（搜索词）和广告、商品、网页的相关性。
而相关性是现代搜索引擎、推荐系统、广告系统的核心要素之一。
主体模型除了用在文本数据上，也可以用在用户行为数据上——此时它就是一个先进的协同过滤推荐系统。

孔雀系统应用在搜索广告、情境广告和目前比较火的广点通系统里。
在前两个产品中，孔雀被用于分析文本数据，归纳自然语言的语义，从而更好地匹配query和广告，以及页面内容和广告。
在广点通中，孔雀被用户理解用户行为数据，从中归纳用户兴趣，从而计算广告和用户兴趣的相关性。

学术界对主题模型的研究从1990年开始。
目前可以从数百万文本中归纳数千语义。
但是2006年开始，Google的Rephil系统就可以从好几个数量级大的文本数据中归纳几十万语义，
从而奠定了Google AdSense广告系统的相关性的基石，最终帮助AdSense成为Google收入的半壁江山。

据说对于这个系统，你酝酿了好多年，是什么样的起因？这中间的设计有过什么样的变化？

最开始我对Rephil很感兴趣，但是因为种种原因，阴差阳错得没能加入那个团队。
同时我感觉自己一直在跟进的一个学术研究方向，有可能发展出一套新的，规模甚于Rephil的主体模型系统。
所以渐渐有“彼可取而代也”的想法。只是验证这个想法，用了四年时间，分成了几个阶段。

最初的想法在Google工作时形成。走的时候，学术界正在研究很火的LDA模型（和Rephil的模型不同）；
并行化方法是MapReduce，这是Google里最有名的并行化框架。
后来发下MapReduce在计算任务安排和分布式文件系统I/O上耗时比实际计算可能还要多，于是尝试使用传统的MPI。
但是MPI不能很好地支持自动错误恢复。于是又改用Google Pregel。
Pregel基于一种称为BSP的并行化思路，几乎和MPI一样久远。
BSP虽然考虑了容错，但是容错需要cache所有进程的通信记录，往往导致内存不够。
从这时起，我渐渐意识到通用的并行计算框架，很难满足主题模型的需要。
同时，我也注意到Google里很多成功的大规模机器学习系统都用自己独特的并行计算框架。

我到腾讯工作之后，仍然想继续这样的研究。
但是当时刚去的时候就一个人，而腾讯的搜索和广告业务在初起阶段，一时之间很难有对基础研究的大规模投入。
于是我放下了这个研究想法，和志同道合的同事们一起专心做了两年多广告业务。
直到业务趋于稳定，我自己也被提升为负责广告算法和策略的技术总监之后，才又开始尝试。

2012年的国庆假期，我用Go语言写了一个尝试性版本。
叫尝试性，是因为这次我换了模型。新的模型基于一种叫hierarchical Dirichlet process（HDP）的数学方法。
有此考虑是因为之前的研究经验让我意识到LDA和其他很多主体模型（包括pLSA、RBM、NMF、SVD等）都不能描述长尾数据，
而是专注于从高频数据中归纳语义，得到的自然是“主流”语义。
可是互联网的精髓在于服务用户的“长尾”需求。 
LDA即便并行化做得很成功，能归纳很多语义，但是去掉重复语义之后，结果往往就几百个主流语义。 
Rephil的模型可以近似描述长尾，但是复制就成了抄袭。
HDP也能描述长尾，但是并行计算非常复杂，很难通过减少进程间的交互，切断数据依赖。
而切断数据依赖是大规模并行计算的基础。所以我们对HDP做了修改，让它计算起来像LDA那么简单。
此外，对并行计算方法也做了很大的改进。
Go语言的开发效率比C++和Java都高很多，让我能在七天假期里尝试新模型和新的并行化方法。
尝试结果从实验效果上看很有潜力，于是我决定开始真正开发一个大规模系统。

当时我负责的团队有几十位工程师，能使用近千台服务器，而且我的上级领导对这个项目非常支持。
但是考虑到我们团队要承担KPI压力，所以实际上除了我，
只有另外两位很年轻的工程师（赵学敏和孙振龙）志愿全职投入，不到团队总人数的十分之一。
当时每天的工作时间主要花在团队管理上，编程的时间都在八点钟下班之后。
这样的经历持续了大半年，直到在400台计算机上的并行训练试验效果初见成效后，有更多同事热情兼职加入。
大家优化了训练系统，也做了很多将研究工作应用于实际业务的工作。

做完这个项目你有什么体会？

从这段经历可见大数据技术推进的不易 ——数学模型的改变和并行计算方法改进密切相关，没法拆开，一部分给学术界，一部分给工业界。
而学术界距离业务比较远，不容易接触到真实的大数据，也很难找到数百台机器，只能在工业界做。
而在工业界势必要平衡业务压力和基础研究两者之间资源分配。
先进的研究往往尚未被大部分人理解，又需要比较长的时间
——要在此期间获得团队（包括研究、工程、产品、销售）的理解和支持，
是对项目主持者的全面考验，需要主持者之前的声誉和撸起袖子来的实干精神，给团队注入信心。
这其中领导的支持当然也非常重要。
一年前我们的团队经历了一次重组，新任领导也是搜索和广告业务的行家，对我们的技术研究仍然非常支持。

春节前有一次聚会，席间我回顾了这段经历。
在座的百度的余凯老师表示理解，总结说：“今日中国是极端的理想主义和极端的现实主义的结合”。
我甚感共鸣，其实古往今来莫非如此。

孔雀之外，把研究成果和业界需求结合后的产品有哪些？

因为我一直在公司里工作，研究都是冲着产品和实用做的。
在Google工作的时候，除了自己努力往Google Orkut、生活搜索、音乐搜索等产品里推广，
同时也有其他产品（Reader、News）的同事主动尝试。
此外，有些结果在开源届有应用。
比如北大的实习生李浩源主导的一个分布式频繁项目挖掘的工作，后来被Apache Mahout系统采用。
我和工程师白红杰开源的pLDA项目也有很多用户。
后来几位实习生同学进一步改进，成了pLDA+。
pLDA和pLDA+一共被200多项后来的工作引用。

在腾讯的时候，你发明了很多新的机器学习和数据挖掘的算法，这些有没有反过来在学术研究界产生贡献？

在腾讯的工作和业界结合更紧密。
因为工作比较忙，没有时间仔细写论文，所以暂时没有论文发表。
但是有一些学术会议上的分享和几个开源软件，包括我用C++写的一个MapReduce的实现http://code.google.com/mapreduce-lite，
以及在此基础上开发的一个并行logistic regression 训练系统 http://github.com/wangkuiyi/lasso。

成长的秘密


“因为大家都敢于创业，所以避免了寡头垄断；而不是因为没有寡头垄断，所以更容易创业成功。”


国内大型互联网企业（如腾讯）和硅谷的互联网企业在管理机制上有什么大差别？

现代互联网企业之间有很多交流和学习，在管理经验和机制上其实大同小异。
当年Google中国的同事在能力上和美国的同事没有什么区别；
腾讯同事的技术水平也和LinkedIn的同事没有什么区别。
如果说有差异，更多是在文化上的。

在国内，人多资源少。
几百年来中国的文化就强调竞争，流传下来的口号也很多，比如“吃得苦中苦，方为人上人”。
为什么要做“人上人”呢？很大程度上是为了多吃多占吧。
当代的中国孩子也是从小就被迫和邻居家孩子比成绩。
长大之后，习惯性地和同事比较年终奖、晋级晋等。
可是太过计较小节，就容易忽视了大方向。
而且自己人之间的恶性竞争，削弱民族凝聚力。

资源竞争也体现在高额的房价上。
房价束缚了很多年轻人——为了攒钱首付，为了能稳定的还贷，在工作中谨小慎微，不敢直言直谏，接受很多苟且和无奈，放弃了成就业务和完备自己的机会。
这和二战后的日本以及我出差时见到的今日印度很像。

在美国，地多人少。
即使在硅谷，由于最近几年大量中国和印度移民涌入，房价提升。
但是换算到每平米单价，仍然在北京上海广州深圳之下很多。
再加上平均工资水平相对较高，在这里留学和工作的年轻人买房时是不需要老父母帮助凑首付的。
在国内普遍三十年还贷，在这里一般是十年之内。

在资源竞争相对宽松的环境下，西方的教育也相对宽松。
强调人格的培养，而不是知识的灌输。中国有句古话“宰相肚里能撑船”，就是有多大胸怀做多大事业的意思。
相对宽松的环境，给人更大的挥洒空间，从而不计小节，就像平生慷慨的班都护和万里间关的马伏波
——他们自己以及我们这些后人恐怕都不在意他们是行政干部几级。
我理解这是硅谷里很多人有更大的胆魄创业的重要原因
——因为大家都敢于创业，所以避免了寡头垄断；而不是因为没有寡头垄断，所以更容易创业成功。

从什么时候开始从事管理工作？更喜欢纯技术工作还是更倾向于技术管理工作？

我更愿意做我喜欢做的事。
如果这件事需要做技术，那就做技术；如果需要做管理，就做管理；如果需要二者兼顾，那么就累一点儿，奋力兼顾一下。

在国内的科技行业，尤其是大公司，有一种说法“三十岁之后就干不动技术了，要尽早转管理”。
其实我也见过很多很早转管理，技术上不再长进，丧失了技术行业的核心竞争力，从而不得不留在大公司混派系的例子。

另一方面，我的同龄人里有很多很出色的榜样。
比如最近在硅谷认识的一位朋友杨文杰——上海交大数学系本科。
读书期间就创业。
毕业后，为了进一步开拓视野，先后在J.P. Morgan（香港）和Summit Partners（美国）工作。
一边工作一边在斯坦福读MBA以了解美国环境。
做了多年准备后，现在又离开大公司在硅谷创业，用人工智能技术支持商业拓展。
他这样在数学、计算机、金融、投资、管理等多个方面努力学习、融会贯通，功底是和扎实的。
而为了做到这些，他每天的体能训练也很扎实。
并且为了保持精神状态，每天洗冷水澡。

另一位在Google认识的大哥王欣宇，在总结自己的职业发展时有一个四字口诀“募投管退”
——他选择的职业发展路线，使得他在募集资金、选择投资业务、管理团队、和公司上市四个方面都有锻炼。

我见到不少朋友给自己打个标签：技术人员或者管理人员，甚至区分工程师和研究员。
其实这些标签往往是一种束缚，而人的本性其实是追寻自由成长的空间的。

在编程语言上，你的选择是什么？都应用在了哪些项目上？

我接触过的编程语言不少，因为对语言很好奇。
随意数数至少包括BASIC、LOGO、6502汇编、Fortran、Pascal、C、C++、80386保护模式汇编、
COBOL、Tcl、Awk、Javascript、C#、LaTeX、Maxima、Maya、
Emacs Lisp、Scheme、Common Lisp、Erlang、Radeon GPU汇编、
Cg、Java、Python、Haskell、Objective-C、Go。
其中对我影响最大的是Lisp，是我的同学王垠教我的，让我接触了一点计算的数学本质。
在微软图形学组实习时学了GPU的汇编语言，后来用GPU写并行机器学习算法的时候用过Cg。
我工作中用的语言主要是C++。
从写Peacock开始用Go。
简单的分布式数据处理用bash+ssh+awk代替MapReduce。

你一路走来加入的都是一些业界闪耀的公司比如IBM，Google，腾讯，以及现在LinkedIn，这是你刻意的选择吗？
你会给计算机相关专业的大学毕业生什么样的择业建议？

我很珍惜我的同事们，他们给了我很多帮助和提示；但没有刻意选择加入大牌公司。
毕竟如吴军在《浪潮之巅》里说的，闪耀的牌子都在一波波的浪潮中过去了
——今天毕业入行的人记得Sun的不多了，知道DEC的基本没有。

我在择业时也有很多茫然不决的时候。
但是我有个好榜样，是原来Hulu.com的engineering VP张小沛。
她对择业的建议很简练：“最重要的是知道自己要的是什么”。

